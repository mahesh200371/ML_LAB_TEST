# -*- coding: utf-8 -*-
"""lab_test_28

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ATqHpMUKnF8aTGm7ijtvCtNuqPd4Uffk
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score
import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline # Added this import

# Assuming df, X_test, y_test, and preprocessor are defined from previous steps.
# To be safe, I will re-create necessary components from the previous successful run.
df = pd.read_csv("/content/drive/MyDrive/SKILLS_LAB/loan_data.csv")

# Define the feature orders and columns
grades = ['A', 'B', 'C', 'D', 'E', 'F']
subgrades = ['1', '2', '3', '4', '5']
grade_subgrade_order = [g + s for g in grades for s in subgrades]

numerical_features = ['annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate']
ordinal_features = ['grade_subgrade']
nominal_features = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose']
drop_features = ['id']

# Re-create preprocessor
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('ord', OrdinalEncoder(categories=[grade_subgrade_order], handle_unknown='use_encoded_value', unknown_value=-1), ordinal_features),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), nominal_features),
        ('drop_cols', 'drop', drop_features)
    ],
    remainder='passthrough'
)

# Separate features (X) and target (y)
X = df.drop('loan_paid_back', axis=1)
y = df['loan_paid_back']

# Split data (using the same random state and split size)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Model Pipeline with Logistic Regression
model_lr = Pipeline(steps=[
    ('preprocessor', preprocessor),
    # Using 'saga' solver for large datasets and potentially high dimensionality from OHE
    ('classifier', LogisticRegression(solver='saga', max_iter=3000, random_state=42, n_jobs=-1))
])

# Section 3: Model Development and Tuning - Training (Logistic Regression)
model_lr.fit(X_train, y_train)

# Predict probabilities on the test set
y_pred_proba_lr = model_lr.predict_proba(X_test)[:, 1]

# Calculate AUC
test_auc_lr = roc_auc_score(y_test, y_pred_proba_lr)

print(f"\n--- Section 3: Model Development and Tuning (Logistic Regression) ---")
print(f"Test Set AUC for Logistic Regression: {test_auc_lr:.4f}")

# Section 4: Subgroup Analysis Setup
# Create a DataFrame for test set results
test_results_lr = X_test.copy()
test_results_lr['loan_paid_back_actual'] = y_test
test_results_lr['loan_paid_back_proba'] = y_pred_proba_lr

# --- Subgroup Analysis Function ---
def calculate_subgroup_auc(df_results, group_col, group_val):
    """Calculates AUC for a specific subgroup."""
    subgroup_df = df_results[df_results[group_col] == group_val]
    if len(subgroup_df) > 1 and len(subgroup_df['loan_paid_back_actual'].unique()) > 1:
        auc = roc_auc_score(subgroup_df['loan_paid_back_actual'], subgroup_df['loan_paid_back_proba'])
        return auc
    return np.nan # Not enough samples or only one class

# --- 1. By education_level ---
education_levels = df['education_level'].unique()
education_auc_lr = {}
for level in education_levels:
    auc = calculate_subgroup_auc(test_results_lr, 'education_level', level)
    education_auc_lr[level] = auc

# --- 2. By loan_purpose ---
loan_purposes = df['loan_purpose'].unique()
purpose_auc_lr = {}
for purpose in loan_purposes:
    auc = calculate_subgroup_auc(test_results_lr, 'loan_purpose', purpose)
    purpose_auc_lr[purpose] = auc

# Sort and get top 3 and bottom 3
purpose_auc_sorted_lr = {k: v for k, v in sorted(purpose_auc_lr.items(), key=lambda item: item[1], reverse=True) if not np.isnan(v)}
top_3_purposes_lr = list(purpose_auc_sorted_lr.items())[:3]
bottom_3_purposes_lr = list(purpose_auc_sorted_lr.items())[-3:]

print("\n--- Section 4: Subgroup Analysis (Logistic Regression) ---")
print("\nAUC by Education Level:")
print(pd.Series(education_auc_lr).dropna().sort_values(ascending=False).to_string(float_format='%.4f'))

print("\nAUC by Loan Purpose (Top 3):")
print(pd.DataFrame(top_3_purposes_lr, columns=['Purpose', 'AUC']).to_string(index=False, float_format='%.4f'))

print("\nAUC by Loan Purpose (Bottom 3):")
print(pd.DataFrame(bottom_3_purposes_lr, columns=['Purpose', 'AUC']).to_string(index=False, float_format='%.4f'))

#ROC curve
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Calculate ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_lr)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

